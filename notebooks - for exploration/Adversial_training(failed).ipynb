{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--imports---\n",
    "import os\n",
    "import scanpy as sc\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3580)\n"
     ]
    }
   ],
   "source": [
    "#---load data and Neuronal Networks---\n",
    "#set base path to load data: goes back one directory and then into the data\n",
    "base_path = os.path.join('..', 'data')\n",
    "#Name of data set\n",
    "dataset_name = 'large_atac_gene_activity'\n",
    "# read dataset into an anndata object:  Category - Cells of the brain\n",
    "inPath = os.path.join(base_path, f\"{dataset_name}.h5ad\")\n",
    "adata = sc.read(inPath)\n",
    "\n",
    "#set base path to load data: goes back one directory and then into the data\n",
    "base_path = os.path.join('..', 'src', 'models', 'saved_models')\n",
    "#Name of autoencoder\n",
    "dataset_name = 'autoencoder_mselossfunction'\n",
    "# load autoencoder\n",
    "inPath = os.path.join(base_path, f\"{dataset_name}.keras\")\n",
    "autoencoder = tf.keras.models.load_model(inPath)\n",
    "\n",
    "#Name of discriminator\n",
    "dataset_name = 'discriminator_pretrained'\n",
    "# load discriminator\n",
    "inPath = os.path.join(base_path, f\"{dataset_name}.keras\")\n",
    "discriminator = tf.keras.models.load_model(inPath)\n",
    "print(discriminator.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---Prepare Data---\n",
    "#ADATA->NUMPY\n",
    "INPUT = adata.X.toarray()\n",
    "\n",
    "\"\"\"\n",
    "removed for testing\n",
    "\"\"\"\n",
    "#Encode the cell labels as One hot vector to use as additional information\n",
    "#encoder = OneHotEncoder(sparse_output=False)  # `sparse=False` returns a dense array\n",
    "#encoded_labels = encoder.fit_transform(adata.obs[['final_cell_label']])\n",
    "# Concatenate gen expreesion matrix with oneHotLabels\n",
    "#INPUT = np.concatenate((X_numpy, encoded_labels), axis=1)\n",
    "\n",
    "#One-hot encoded Batches\n",
    "encoder = OneHotEncoder(sparse_output=False)  # `sparse=False` returns a dense array\n",
    "OUTPUT = encoder.fit_transform(adata.obs[['batchname_all']])\n",
    "OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3587)\n",
      "tf.Tensor(\n",
      "[1.05611710e-02 2.02902779e-03 4.36092820e-03 5.02762850e-03\n",
      " 6.56732358e-03 1.02326252e-01 1.90089177e-03 2.93324934e-03\n",
      " 2.05984013e-03 3.25875403e-03 6.48334622e-02 1.11935735e-02\n",
      " 5.98306162e-03 2.41488498e-03 9.33957193e-03 3.80708324e-03\n",
      " 5.61946201e+00 1.29462034e-01 3.99731332e-03 3.58747900e-03\n",
      " 2.89640203e-03 3.89555260e-03 3.86752840e-03 5.10721328e-03\n",
      " 8.01295638e-02 1.88323352e-02 9.47573222e-03 5.61399013e-03\n",
      " 4.86520386e+00 1.58708449e-03], shape=(30,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test = np.concatenate((INPUT[0:30], encoded_labels[0:30]), axis=1)\n",
    "results = discriminator(test)\n",
    "entropy = tf.keras.losses.categorical_crossentropy(OUTPUT[0:30], results)\n",
    "print(test.shape)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3580)\n",
      "INPUT shape: (3580,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3580), dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(autoencoder.input_shape)\n",
    "print(\"INPUT shape:\", INPUT[0].shape)\n",
    "autoencoder(INPUT[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred shape(30, 3580)\n",
      "real answer shape(30, 11)\n",
      "discriminator_predictions shape(30, 11)\n",
      "tf.Tensor(\n",
      "[0.22242995 0.317155   1.0178852  0.08984765 0.29704508 2.4212985\n",
      " 0.21578556 0.08989855 0.6468312  0.13315095 5.5451536  1.4344335\n",
      " 0.36133453 0.26281253 1.6896727  0.14549033 4.065153   2.3337574\n",
      " 0.22413823 0.2962553  0.12029588 1.3646559  0.35546654 0.26149848\n",
      " 1.7381909  2.2296028  0.77218586 0.5642071  7.23871    0.25411874], shape=(30,), dtype=float32)\n",
      "tf.Tensor(-1.2236154, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from numpy import average\n",
    "\n",
    "\n",
    "y_pred = autoencoder(INPUT[0:30])\n",
    "print(f\"y_pred shape{y_pred.shape}\")\n",
    "expected_batch = OUTPUT[0:30]\n",
    "print(f\"real answer shape{expected_batch.shape}\") \n",
    "discriminator_predictions = discriminator(y_pred)\n",
    "print(f\"discriminator_predictions shape{discriminator_predictions.shape}\")\n",
    "\n",
    "CCE = tf.keras.losses.categorical_crossentropy(expected_batch, discriminator_predictions)\n",
    "print(CCE)\n",
    "CCE = -tf.math.reduce_mean(CCE)\n",
    "print(CCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84813, 3580)\n",
      "(None, 3580)\n",
      "(None, 3580)\n",
      "Epoch 1/10\n",
      "Tensor(\"functional_2_1/sequential_1_2/dense_1_1/Relu:0\", shape=(None, 3580), dtype=float32)\n",
      "y_pred shape: (None, 3580)\n",
      "real answer shape(None, 11)\n",
      "discriminator_predictions shape(None, 11)\n",
      "Tensor(\"compile_loss/lossfunction/softmax_cross_entropy_with_logits/Reshape_2:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"compile_loss/lossfunction/Neg:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Mean.update_state() got multiple values for argument 'sample_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(discriminator\u001b[38;5;241m.\u001b[39minput_shape)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Continue training your generator - use the consistent variable name\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mINPUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINPUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[0;32m     35\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lklei\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\lklei\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py:21\u001b[0m, in \u001b[0;36mMetricsList.update_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics:\n\u001b[1;32m---> 21\u001b[0m         \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Mean.update_state() got multiple values for argument 'sample_weight'"
     ]
    }
   ],
   "source": [
    "def fool_discriminator_loss(discriminator, expected_output):\n",
    "    def lossfunction(y_true, y_pred):\n",
    "        print(y_pred)\n",
    "        # Extract the first 30 states for testing\n",
    "        expected_batch =  discriminator(y_true)\n",
    "        print(f\"y_pred shape: {y_pred.shape}\")\n",
    "        print(f\"real answer shape{expected_batch.shape}\")\n",
    "        # Pass autoencoder output to the discriminator\n",
    "        discriminator_predictions = discriminator(y_pred)\n",
    "        print(f\"discriminator_predictions shape{discriminator_predictions.shape}\")\n",
    "        # Calculate the loss\n",
    "        CCE = tf.keras.losses.categorical_crossentropy(expected_batch, discriminator_predictions)\n",
    "        print(CCE)\n",
    "        CCE = -tf.math.reduce_mean(CCE)\n",
    "        print(CCE)\n",
    "        # We want to maximize CCE (discriminator being wrong), so we minimize -CCE\n",
    "        return CCE  # Much safer than 1/CCE\n",
    "    \n",
    "    return lossfunction\n",
    "\n",
    "# Compile your autoencoder with the new loss\n",
    "autoencoder.compile(\n",
    "    optimizer=autoencoder.optimizer,\n",
    "    loss=fool_discriminator_loss(discriminator, OUTPUT),\n",
    "    metrics=autoencoder.metrics\n",
    ")\n",
    "print(INPUT.shape)\n",
    "print(autoencoder.input_shape)\n",
    "print(discriminator.input_shape)\n",
    "# Continue training your generator - use the consistent variable name\n",
    "autoencoder.fit(\n",
    "    INPUT, INPUT,\n",
    "    epochs=10,\n",
    "    batch_size=30\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
